# SimEval: Distributed AI Evaluation Platform

SimEval is a microservices-based platform designed to simulate, stress-test, and evaluate Large Language Model (LLM) interactions in a distributed environment. It orchestrates a "Red Team" vs. "Blue Team" scenario where a chaos engine generates diverse user personas to test an AI Gateway's robustness and safety alignment.

## üèó Architecture

The platform consists of the following Dockerized components:

### 1. AI Gateway (`ai-gateway`)
- **Role**: The core "System Under Test" and "Judge".
- **Tech**: Python, FastAPI, AsyncIO.
- **Function**:
  - **Target Mode**: Acts as a chatbot interface, forwarding requests to a local LLM (Ollama).
  - **Judge Mode**: Evaluates the safety of responses generated by the Target.
- **Metrics**: Exposes Prometheus metrics for request throughput, latency, and safety violations, tagged by user persona.

### 2. Chaos Engine (`chaos-engine`)
- **Role**: The Load Generator.
- **Tech**: Go (Golang).
- **Function**: Simulates concurrent users with distinct personas (e.g., "Hacker", "Angry User", "Developer").
- **Behavior**: Sends high-volume traffic to the AI Gateway to test system stability and safety guardrails.

### 3. Observability Stack
- **Prometheus**: Scrapes metrics from the AI Gateway.
- **Grafana**: Visualizes system health, including:
  - Real-time Request Throughput (RPM).
  - Inference Latency.
  - Safety Violation Events.
  - Traffic breakdown by Persona.

### 4. LLM Backend
- **Ollama**: Runs local LLMs (e.g., Llama 3, Gemma) to provide inference capabilities without external API dependencies.

## üöÄ Getting Started

### Prerequisites
- Docker & Docker Compose
- [Optional] Go 1.21+ (for local development)

### Running the Platform

1. **Start the Stack**
   ```bash
   docker-compose up -d --build
   ```

2. **Access the Dashboard**
   - Open Grafana at [http://localhost:3000](http://localhost:3000).
   - Navigate to the **Sim-Eval Command Center** dashboard.

3. **Monitor Traffic**
   - The Chaos Engine will automatically start generating traffic.
   - Watch the dashboard for real-time metrics on throughput and safety.

## üõ† Configuration

- **Concurrency**: Adjust `TotalWorkers` in `chaos-engine/main.go` to scale the load.
- **LLM Model**: Configure the model in `docker-compose.yml` (default: `gemma:2b`).

## üìä Dashboard Features

- **Traffic Load (RPM)**: Visualizes the volume of requests per minute.
- **Latency Gauge**: Monitors the responsiveness of the LLM.
- **Safety Violations**: Tracks "UNSAFE" responses detected by the Judge.
- **Persona Traffic**: Breaks down traffic sources by simulated user type.
